{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import LeakyReLU, concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import Stemmer\n",
    "\n",
    "# Other\n",
    "import os,re\n",
    "import timeit\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.engine import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "def reverse_gradient(X, hp_lambda):\n",
    "    '''Flips the sign of the incoming gradient during training.'''\n",
    "    try:\n",
    "        reverse_gradient.num_calls += 1\n",
    "    except AttributeError:\n",
    "        reverse_gradient.num_calls = 1\n",
    "\n",
    "    grad_name = \"GradientReversal%d\" % reverse_gradient.num_calls\n",
    "\n",
    "    @tf.RegisterGradient(grad_name)\n",
    "    def _flip_gradients(op, grad):\n",
    "        return [tf.negative(grad) * hp_lambda]\n",
    "\n",
    "    g = K.get_session().graph\n",
    "    with g.gradient_override_map({'Identity': grad_name}):\n",
    "        y = tf.identity(X)\n",
    "\n",
    "    return y\n",
    "\n",
    "class GradientReversal(Layer):\n",
    "    '''Flip the sign of gradient during training.'''\n",
    "    def __init__(self, hp_lambda, **kwargs):\n",
    "        super(GradientReversal, self).__init__(**kwargs)\n",
    "        self.supports_masking = False\n",
    "        self.hp_lambda = hp_lambda\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.trainable_weights = []\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return reverse_gradient(x, self.hp_lambda)\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'hp_lambda': self.hp_lambda}\n",
    "        base_config = super(GradientReversal, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12315 entries, 0 to 12314\n",
      "Data columns (total 4 columns):\n",
      "id       12315 non-null int64\n",
      "label    12315 non-null object\n",
      "name     12315 non-null object\n",
      "text     12315 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 384.9+ KB\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572342978255048705</td>\n",
       "      <td>racism</td>\n",
       "      <td>thefoxbandit</td>\n",
       "      <td>so drasko just said he was impressed the girls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>572341498827522049</td>\n",
       "      <td>racism</td>\n",
       "      <td>patricia</td>\n",
       "      <td>drasko they didn't cook half a bird you idiot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>572340476503724032</td>\n",
       "      <td>racism</td>\n",
       "      <td>food</td>\n",
       "      <td>hopefully someone cooks drasko in the next ep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572334712804384768</td>\n",
       "      <td>racism</td>\n",
       "      <td>lil</td>\n",
       "      <td>of course you were born in serbia...you're as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>572332655397629952</td>\n",
       "      <td>racism</td>\n",
       "      <td>jlwhitaker</td>\n",
       "      <td>these girls are the equivalent of the irritati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>575949086055997440</td>\n",
       "      <td>racism</td>\n",
       "      <td>dominiquew</td>\n",
       "      <td>#mkr  lost the plot - where's the big texan wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>551659627872415744</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@lauracdean i love how the islamofascists recr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>551763146877452288</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@ibnhlophe @eeviewonders @anjemchoudary a crim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>551768543277355009</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@anjemchoudary nothing desperate about it. hum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>551769061055811584</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@anjemchoudary idiots like you making such dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>551769698917167104</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@anjemchoudary your prophet was a rapist, murd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>551779988567891969</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@anjemchoudary maybe you can give a talk about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>551783732466577408</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@jonsnowc4 @swatigauri when an islamolunatic b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>551787027725705216</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@remy119 israel is only trying to defend itsel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>551787273256050688</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@remy119 the muslims have exterminated christi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>551787717168619521</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@remy119 muslims are fighting with every relig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>551796768623435776</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>it seems that allah sits around all day obsess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>551797843472556032</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>in islam women must be locked in their houses,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>551798472827883520</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>islam considers women as one big sex organ, so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>551799120080293888</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>to muslims a woman walking down the street is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id   label          name  \\\n",
       "0   572342978255048705  racism  thefoxbandit   \n",
       "1   572341498827522049  racism      patricia   \n",
       "2   572340476503724032  racism          food   \n",
       "3   572334712804384768  racism           lil   \n",
       "4   572332655397629952  racism    jlwhitaker   \n",
       "5   575949086055997440  racism    dominiquew   \n",
       "6   551659627872415744  racism    vile_islam   \n",
       "7   551763146877452288  racism    vile_islam   \n",
       "8   551768543277355009  racism    vile_islam   \n",
       "9   551769061055811584  racism    vile_islam   \n",
       "10  551769698917167104  racism    vile_islam   \n",
       "11  551779988567891969  racism    vile_islam   \n",
       "12  551783732466577408  racism    vile_islam   \n",
       "13  551787027725705216  racism    vile_islam   \n",
       "14  551787273256050688  racism    vile_islam   \n",
       "15  551787717168619521  racism    vile_islam   \n",
       "16  551796768623435776  racism    vile_islam   \n",
       "17  551797843472556032  racism    vile_islam   \n",
       "18  551798472827883520  racism    vile_islam   \n",
       "19  551799120080293888  racism    vile_islam   \n",
       "\n",
       "                                                 text  \n",
       "0   so drasko just said he was impressed the girls...  \n",
       "1   drasko they didn't cook half a bird you idiot ...  \n",
       "2   hopefully someone cooks drasko in the next ep ...  \n",
       "3   of course you were born in serbia...you're as ...  \n",
       "4   these girls are the equivalent of the irritati...  \n",
       "5   #mkr  lost the plot - where's the big texan wi...  \n",
       "6   @lauracdean i love how the islamofascists recr...  \n",
       "7   @ibnhlophe @eeviewonders @anjemchoudary a crim...  \n",
       "8   @anjemchoudary nothing desperate about it. hum...  \n",
       "9   @anjemchoudary idiots like you making such dec...  \n",
       "10  @anjemchoudary your prophet was a rapist, murd...  \n",
       "11  @anjemchoudary maybe you can give a talk about...  \n",
       "12  @jonsnowc4 @swatigauri when an islamolunatic b...  \n",
       "13  @remy119 israel is only trying to defend itsel...  \n",
       "14  @remy119 the muslims have exterminated christi...  \n",
       "15  @remy119 muslims are fighting with every relig...  \n",
       "16  it seems that allah sits around all day obsess...  \n",
       "17  in islam women must be locked in their houses,...  \n",
       "18  islam considers women as one big sex organ, so...  \n",
       "19  to muslims a woman walking down the street is ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data_path = \"encoded_data/\"\n",
    "\n",
    "tweet_df = pd.read_pickle(encoded_data_path + \"tweets.pkl\")\n",
    "\n",
    "tweet_df.info()\n",
    "print(\"\\n\")\n",
    "tweet_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id\n",
      "count  1.231500e+04\n",
      "mean   5.619213e+17\n",
      "std    4.051089e+16\n",
      "min    3.193999e+17\n",
      "25%    5.641296e+17\n",
      "50%    5.710391e+17\n",
      "75%    5.756380e+17\n",
      "max    6.847790e+17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neither    5850\n",
       "sexism     4341\n",
       "racism     2074\n",
       "both         50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tweet_df.describe())\n",
    "\n",
    "tweet_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570620699166912512</td>\n",
       "      <td>neither</td>\n",
       "      <td>misandrist</td>\n",
       "      <td>a few people poked me yesterday, but i was up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>563378042509082624</td>\n",
       "      <td>neither</td>\n",
       "      <td>misandrist</td>\n",
       "      <td>rt @mikemetcalf: i love misty mornings at bliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>567440148187459584</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@jukes303 unlike you i do read before making a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>555914915928899584</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@hafisabidrees you animals are slitting throat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>603665587017949184</td>\n",
       "      <td>neither</td>\n",
       "      <td>queer</td>\n",
       "      <td>rt @lavender_blume: if you're a man applauding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>396281466205663233</td>\n",
       "      <td>sexism</td>\n",
       "      <td>@yesyouresexist</td>\n",
       "      <td>rt @onnionion \"i'll be ready in 5 minutes\" fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>569605731386728449</td>\n",
       "      <td>neither</td>\n",
       "      <td>misandrist</td>\n",
       "      <td>@srhbutts poor @grimachu. it's not that he wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>564172341144330240</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@buttercupashby @madasahatter_17 mohammed ran ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>573423922764365825</td>\n",
       "      <td>sexism</td>\n",
       "      <td>jay</td>\n",
       "      <td>shut up katie and nikki... that is all :)\\n#mk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>540529698208362496</td>\n",
       "      <td>sexism</td>\n",
       "      <td>@yesyouresexist</td>\n",
       "      <td>\"no offense.\" @nigelbigmeech i'm not sexist bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>564473884527697920</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>@vandaliser @sajid_fairooz @israeliregime moha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>596165409029496833</td>\n",
       "      <td>neither</td>\n",
       "      <td>misandrist</td>\n",
       "      <td>@warrior_tank randi#1266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>572339019238940672</td>\n",
       "      <td>sexism</td>\n",
       "      <td>joshua</td>\n",
       "      <td>@mykitchenrules did you find katie and nikki i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>575951228368089088</td>\n",
       "      <td>sexism</td>\n",
       "      <td>김경현</td>\n",
       "      <td>\"@fee_bee_63: kat is a completely rank cow but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>563093253378289665</td>\n",
       "      <td>neither</td>\n",
       "      <td>misandrist</td>\n",
       "      <td>lrt did not appear to be snark. o_o.  pretty s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>568190615525003265</td>\n",
       "      <td>racism</td>\n",
       "      <td>vile_islam</td>\n",
       "      <td>rt @canine_rights: @kizzycoy1 exactly, is this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>575371330331152384</td>\n",
       "      <td>sexism</td>\n",
       "      <td>metal</td>\n",
       "      <td>feminazi snowflakes ♫♪\\nfeminazi snowflakes ♫♪...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>571836750542188545</td>\n",
       "      <td>sexism</td>\n",
       "      <td>♥❤</td>\n",
       "      <td>@srhbutts @thatsabinegirl \"yeah this sounds li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>599707514490388480</td>\n",
       "      <td>neither</td>\n",
       "      <td>misandrist</td>\n",
       "      <td>i was about to comment \"found the mra\" but the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>576462138073448448</td>\n",
       "      <td>neither</td>\n",
       "      <td>misandrist</td>\n",
       "      <td>@the_duke_gaming press requests need to come i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id    label             name  \\\n",
       "0   570620699166912512  neither       misandrist   \n",
       "1   563378042509082624  neither       misandrist   \n",
       "2   567440148187459584   racism       vile_islam   \n",
       "3   555914915928899584   racism       vile_islam   \n",
       "4   603665587017949184  neither            queer   \n",
       "5   396281466205663233   sexism  @yesyouresexist   \n",
       "6   569605731386728449  neither       misandrist   \n",
       "7   564172341144330240   racism       vile_islam   \n",
       "8   573423922764365825   sexism              jay   \n",
       "9   540529698208362496   sexism  @yesyouresexist   \n",
       "10  564473884527697920   racism       vile_islam   \n",
       "11  596165409029496833  neither       misandrist   \n",
       "12  572339019238940672   sexism           joshua   \n",
       "13  575951228368089088   sexism              김경현   \n",
       "14  563093253378289665  neither       misandrist   \n",
       "15  568190615525003265   racism       vile_islam   \n",
       "16  575371330331152384   sexism            metal   \n",
       "17  571836750542188545   sexism               ♥❤   \n",
       "18  599707514490388480  neither       misandrist   \n",
       "19  576462138073448448  neither       misandrist   \n",
       "\n",
       "                                                 text  \n",
       "0   a few people poked me yesterday, but i was up ...  \n",
       "1   rt @mikemetcalf: i love misty mornings at bliz...  \n",
       "2   @jukes303 unlike you i do read before making a...  \n",
       "3   @hafisabidrees you animals are slitting throat...  \n",
       "4   rt @lavender_blume: if you're a man applauding...  \n",
       "5   rt @onnionion \"i'll be ready in 5 minutes\" fro...  \n",
       "6   @srhbutts poor @grimachu. it's not that he wou...  \n",
       "7   @buttercupashby @madasahatter_17 mohammed ran ...  \n",
       "8   shut up katie and nikki... that is all :)\\n#mk...  \n",
       "9   \"no offense.\" @nigelbigmeech i'm not sexist bu...  \n",
       "10  @vandaliser @sajid_fairooz @israeliregime moha...  \n",
       "11                           @warrior_tank randi#1266  \n",
       "12  @mykitchenrules did you find katie and nikki i...  \n",
       "13  \"@fee_bee_63: kat is a completely rank cow but...  \n",
       "14  lrt did not appear to be snark. o_o.  pretty s...  \n",
       "15  rt @canine_rights: @kizzycoy1 exactly, is this...  \n",
       "16  feminazi snowflakes ♫♪\\nfeminazi snowflakes ♫♪...  \n",
       "17  @srhbutts @thatsabinegirl \"yeah this sounds li...  \n",
       "18  i was about to comment \"found the mra\" but the...  \n",
       "19  @the_duke_gaming press requests need to come i...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling \n",
    "tweet_df = tweet_df.sample(frac=1).reset_index(drop=True)\n",
    "tweet_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id\n",
      "count  1.231500e+04\n",
      "mean   5.619213e+17\n",
      "std    4.051089e+16\n",
      "min    3.193999e+17\n",
      "25%    5.641296e+17\n",
      "50%    5.710391e+17\n",
      "75%    5.756380e+17\n",
      "max    6.847790e+17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "neither    5850\n",
       "sexism     4341\n",
       "racism     2074\n",
       "both         50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tweet_df.describe())\n",
    "tweet_df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!!!\n"
     ]
    }
   ],
   "source": [
    "op_file = \"dataset/cleaned_tweet_data.csv\"\n",
    "\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "stemmer = Stemmer.Stemmer('english', 100000)    \n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    #Remove puncuation\n",
    "    #text = text.translate(string.punctuation)\n",
    "    \n",
    "    #split based on everything except a-z0-9_'.\\-\n",
    "    tokens = re.findall(\"[a-z0-9_'.\\-]+\", text.lower())\n",
    "    #tokens = text.lower().split()\n",
    "    \n",
    "    tokens = [stemmer.stemWord(w) for w in tokens if not w in stopWords and len(w) > 2 and len(w)<20]\n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def build_data(df):\n",
    "      \n",
    "    data = pd.DataFrame()\n",
    "    \n",
    "    #cleaning text\n",
    "    data['tweet'] = df['text'].map(lambda x: clean_text(x))    \n",
    "    \n",
    "    data['label'] = df['label']\n",
    "    \n",
    "    data['racism'] = df['label'].map(lambda x: 1 if x == 'racism' else 0)\n",
    "    data['sexism'] = df['label'].map(lambda x: 1 if x == 'sexism' else 0)\n",
    "    data['neither'] = df['label'].map(lambda x: 1 if x == 'neither' else 0)\n",
    "    data['both'] = df['label'].map(lambda x: 1 if x == 'both' else 0)\n",
    "    \n",
    "    # set hate 1 if label is racism/sexism/both\n",
    "    data['hate'] = df['label'].map(lambda x: 0 if x == 'neither' else 1)    \n",
    "    \n",
    "    #label =  {1:hate, 0:non-hate}\n",
    "    labels_hate = data['hate'].map(lambda x : 1 if int(x) == 1 else 0)\n",
    "    \n",
    "    #label =  {1:hate, 0:non-hate}\n",
    "    labels_racist = data['racism'].map(lambda x : 1 if int(x) == 1 else 0)\n",
    "    \n",
    "    data.to_csv(op_file)\n",
    "    \n",
    "    return (data, labels_hate, labels_racist)\n",
    "\n",
    "data, labels_hate, labels_racist  = build_data(tweet_df)\n",
    "print(\"Done!!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12315 entries, 0 to 12314\n",
      "Data columns (total 7 columns):\n",
      "tweet      12315 non-null object\n",
      "label      12315 non-null object\n",
      "racism     12315 non-null int64\n",
      "sexism     12315 non-null int64\n",
      "neither    12315 non-null int64\n",
      "both       12315 non-null int64\n",
      "hate       12315 non-null int64\n",
      "dtypes: int64(5), object(2)\n",
      "memory usage: 673.6+ KB\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>racism</th>\n",
       "      <th>sexism</th>\n",
       "      <th>neither</th>\n",
       "      <th>both</th>\n",
       "      <th>hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>peopl poke yesterday eyebal meetings. respond ...</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mikemetcalf love misti morn blizzard http t.co...</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jukes303 unlik read make assumptions. read qur...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hafisabidre anim slit throat suppos care offen...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lavender_blum man applaud blameonenotal need l...</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>onnionion i'll readi minut girl usual mean i'l...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>srhbutt poor grimachu. date sjws bot sjw conve...</td>\n",
       "      <td>neither</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>buttercupashbi madasahatter_17 moham ran two j...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>shut kati nikki... mkr mkr2015 mykitchenrul</td>\n",
       "      <td>sexism</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>offense. nigelbigmeech i'm sexist women realli...</td>\n",
       "      <td>sexism</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet    label  racism  sexism  \\\n",
       "0  peopl poke yesterday eyebal meetings. respond ...  neither       0       0   \n",
       "1  mikemetcalf love misti morn blizzard http t.co...  neither       0       0   \n",
       "2  jukes303 unlik read make assumptions. read qur...   racism       1       0   \n",
       "3  hafisabidre anim slit throat suppos care offen...   racism       1       0   \n",
       "4  lavender_blum man applaud blameonenotal need l...  neither       0       0   \n",
       "5  onnionion i'll readi minut girl usual mean i'l...   sexism       0       1   \n",
       "6  srhbutt poor grimachu. date sjws bot sjw conve...  neither       0       0   \n",
       "7  buttercupashbi madasahatter_17 moham ran two j...   racism       1       0   \n",
       "8        shut kati nikki... mkr mkr2015 mykitchenrul   sexism       0       1   \n",
       "9  offense. nigelbigmeech i'm sexist women realli...   sexism       0       1   \n",
       "\n",
       "   neither  both  hate  \n",
       "0        1     0     0  \n",
       "1        1     0     0  \n",
       "2        0     0     1  \n",
       "3        0     0     1  \n",
       "4        1     0     0  \n",
       "5        0     0     1  \n",
       "6        1     0     0  \n",
       "7        0     0     1  \n",
       "8        0     0     1  \n",
       "9        0     0     1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "print(\"\\n\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Find correlation between columns\n",
    "\n",
    "def plot_correlation(data, size=8):\n",
    "    corr= data.corr()\n",
    "    fig, ax =plt.subplots(figsize=(size,size))\n",
    "    ax.matshow(corr)\n",
    "    plt.xticks(range(len(corr.columns)),corr.columns)\n",
    "    plt.yticks(range(len(corr.columns)),corr.columns)\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neither    5850\n",
      "sexism     4341\n",
      "racism     2074\n",
      "both         50\n",
      "Name: label, dtype: int64\n",
      "\n",
      "hate(1) and non-hate(0) label count:-\n",
      "\n",
      "1    6465\n",
      "0    5850\n",
      "Name: hate, dtype: int64\n",
      "\n",
      "racism(1) and non-racism(0) label count:-\n",
      "\n",
      "0    10241\n",
      "1     2074\n",
      "Name: racism, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(data['label'].value_counts())\n",
    "\n",
    "print(\"\\nhate(1) and non-hate(0) label count:-\\n\")\n",
    "print(data['hate'].value_counts())\n",
    "\n",
    "\n",
    "print(\"\\nracism(1) and non-racism(0) label count:-\\n\")\n",
    "print(data['racism'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len_of_tweet: 20 \n",
      "\n",
      "kat amp andr cartoon characters.kat develop sportsmanship amp andr grow ball amp take like man mkr cantcook http t.co 9nd2guhgh0\n",
      "\n",
      "length of top 200 tweets:-\n",
      " [20, 20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]\n",
      "\n",
      "number of words:  116283\n",
      "number of unique words:  21351\n"
     ]
    }
   ],
   "source": [
    "# max tweet length\n",
    "\n",
    "tweets = data['tweet'].values\n",
    "\n",
    "max_len = 0\n",
    "max_len_tweet = \"\"\n",
    "len_data = []\n",
    "words = []\n",
    "\n",
    "for t in tweets:\n",
    "    len_data.append(len(t.split()))\n",
    "    words += t.split()\n",
    "    if len(t.split()) > max_len:\n",
    "        max_len = len(t.split())\n",
    "        max_len_tweet = t\n",
    "        \n",
    "\n",
    "VOCAB_SIZE = len(set(words))\n",
    "        \n",
    "print(\"max_len_of_tweet:\", max_len,\"\\n\")\n",
    "print(max_len_tweet)\n",
    "\n",
    "print(\"\\nlength of top 200 tweets:-\\n\",sorted(len_data, reverse = True)[:400])\n",
    "\n",
    "print(\"\\nnumber of words: \", len(words))\n",
    "print(\"number of unique words: \", VOCAB_SIZE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sample shape: (12315, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12315, 20)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MAX_SENT_LEN2 = 20\n",
    "\n",
    "def process_data2(sample):  \n",
    "    # Keras tokenizer function to tokenize the strings and \n",
    "    #‘texts_to_sequences’ to make sequences of words.\n",
    "\n",
    "    #Maximum number of words to work with \n",
    "    #if set, tokenization will be restricted to the top nb_words most common words in the dataset).\n",
    "    tokenizer = Tokenizer(num_words= VOCAB_SIZE)\n",
    "\n",
    "    #fit_on_texts(texts):\n",
    "    #Arguments: list of texts to train on.\n",
    "    #tokenizer.fit_on_texts(data['tweet'])\n",
    "    tokenizer.fit_on_texts(sample)\n",
    "\n",
    "    #texts_to_sequences(texts)\n",
    "    #texts: list of texts to turn to sequences.\n",
    "    #Return: list of sequences (one per text input).\n",
    "    \n",
    "    #sequences = tokenizer.texts_to_sequences(data['tweet'])\n",
    "    sequences = tokenizer.texts_to_sequences(sample)\n",
    "    sample = pad_sequences(sequences, maxlen = MAX_SENT_LEN2)\n",
    "    \n",
    "    print(\"Processed sample shape:\", sample.shape)\n",
    "    #print(\"Sample1:\", sample[0])\n",
    "    \n",
    "    return sample\n",
    "\n",
    "\n",
    "data_embedding2 = process_data2(data['tweet'])\n",
    "data_embedding2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peopl poke yesterday eyebal meetings. respond later morning. \n",
      "\n",
      "[   0    0    0    0    0    0    0    0    0    0    0    0   13 2072\n",
      " 1488 5331 3429  579  480 2073]\n"
     ]
    }
   ],
   "source": [
    "print(data['tweet'][0], \"\\n\")\n",
    "print(data_embedding2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(len(data_embedding2)*.8)\n",
    "\n",
    "x2 = data_embedding2\n",
    "\n",
    "# converting to numpy array\n",
    "#y = labels.values\n",
    "y2_hate = labels_hate\n",
    "y2_racism = labels_racist\n",
    "\n",
    "#x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size = split_size)\n",
    "\n",
    "x2_train = x2[:split_size]\n",
    "x2_test = x2[split_size:]\n",
    "\n",
    "y2_hate_train = y2_hate[:split_size]\n",
    "y2_hate_test = y2_hate[split_size:]\n",
    "\n",
    "y2_racism_train = y2_racism[:split_size]\n",
    "y2_racism_test = y2_racism[split_size:]\n",
    "\n",
    "# transform labels into one hot representation\n",
    "y2_hate_train_one_hot = (np.arange(np.max(y2_hate_train) + 1) == y2_hate_train[:, None]).astype(float)\n",
    "y2_hate_test_one_hot = (np.arange(np.max(y2_hate_test) + 1) == y2_hate_test[:, None]).astype(float)\n",
    "\n",
    "y2_racism_train_one_hot = (np.arange(np.max(y2_racism_train) + 1) == y2_racism_train[:, None]).astype(float)\n",
    "y2_racism_test_one_hot = (np.arange(np.max(y2_racism_test) + 1) == y2_racism_test[:, None]).astype(float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hate Train split:\n",
      "1    5149\n",
      "0    4703\n",
      "Name: hate, dtype: int64\n",
      "1    0.522635\n",
      "0    0.477365\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "\n",
      "Hate Test split:\n",
      "1    1316\n",
      "0    1147\n",
      "Name: hate, dtype: int64\n",
      "1    0.534308\n",
      "0    0.465692\n",
      "Name: hate, dtype: float64\n",
      "\n",
      "Racism Train split:\n",
      "0    8209\n",
      "1    1643\n",
      "Name: racism, dtype: int64\n",
      "0    0.833232\n",
      "1    0.166768\n",
      "Name: racism, dtype: float64\n",
      "\n",
      "\n",
      "Racism Test split:\n",
      "0    2032\n",
      "1     431\n",
      "Name: racism, dtype: int64\n",
      "0    0.82501\n",
      "1    0.17499\n",
      "Name: racism, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Hate Train split:\")\n",
    "print(y2_hate_train.value_counts())\n",
    "print(y2_hate_train.value_counts()/len(y2_hate_train))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Hate Test split:\")\n",
    "print(y2_hate_test.value_counts())\n",
    "print(y2_hate_test.value_counts()/len(y2_hate_test))\n",
    "\n",
    "\n",
    "print(\"\\nRacism Train split:\")\n",
    "print(y2_racism_train.value_counts())\n",
    "print(y2_racism_train.value_counts()/len(y2_racism_train))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Racism Test split:\")\n",
    "print(y2_racism_test.value_counts())\n",
    "print(y2_racism_test.value_counts()/len(y2_racism_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Model...\n",
      "Train on 9852 samples, validate on 2463 samples\n",
      "Epoch 1/10\n",
      "9852/9852 [==============================] - 57s 6ms/step - loss: 0.3679 - acc: 0.8302 - val_loss: 0.2564 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.89931, saving model to encoded_data/weights-improvement-01-0.8993.hdf5\n",
      "Epoch 2/10\n",
      "2080/9852 [=====>........................] - ETA: 42s - loss: 0.1343 - acc: 0.9534"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-621433b814d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m               \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m               \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m               validation_data = (x2_test, y2_hate_test_one_hot))\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "VOCAB_SIZE = 21351\n",
    "\n",
    "INP_DIM = x2_train.shape[1]\n",
    "EMBED_DIM = 128\n",
    "OP_DIM = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, EMBED_DIM, input_length = INP_DIM))\n",
    "model.add(LSTM(200, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "\n",
    "\n",
    "\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# creating checkpoint to save model every time validation accuracy improves\n",
    "filepath = encoded_data_path + \"weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print('\\n\\nTraining Model...')\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#batch_size: Integer or None. Number of samples per gradient update. \n",
    "#If unspecified, batch_size will default to 32.\n",
    "\n",
    "model.fit(x2_train, y2_hate_train_one_hot,\n",
    "              batch_size = BATCH_SIZE,\n",
    "              epochs = EPOCHS,\n",
    "              callbacks = callbacks_list,\n",
    "              validation_data = (x2_test, y2_hate_test_one_hot))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2463,) (2463, 2) <class 'pandas.core.series.Series'> <class 'numpy.ndarray'>\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1024  142]\n",
      " [  91 1206]]\n",
      "\n",
      "Classification Matrix:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.88      0.90      1166\n",
      "          1       0.89      0.93      0.91      1297\n",
      "\n",
      "avg / total       0.91      0.91      0.91      2463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lstm_hate = load_model(encoded_data_path +  'weights-improvement-02-0.9054.hdf5')\n",
    "\n",
    "y2_predicted = model_lstm_hate.predict(x2_test)\n",
    "print(y2_hate_test.shape, y2_predicted.shape, type(y2_hate_test), type(y2_predicted))\n",
    "\n",
    "y2_predicted_ = y2_predicted.argmax(axis=1)\n",
    "\n",
    "print ('\\nConfusion Matrix:')\n",
    "print (confusion_matrix(y2_hate_test, y2_predicted_))\n",
    "\n",
    "\n",
    "print ('\\nClassification Matrix:')\n",
    "print (classification_report(y2_hate_test, y2_predicted_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training Model...\n",
      "Train on 9852 samples, validate on 2463 samples\n",
      "Epoch 1/10\n",
      "9852/9852 [==============================] - 162s 16ms/step - loss: 0.1311 - acc: 0.9578 - val_loss: 0.0770 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.97726, saving model to encoded_data/weights-racism-improvement-01-0.9773.hdf5\n",
      "Epoch 2/10\n",
      "9852/9852 [==============================] - 152s 15ms/step - loss: 0.0206 - acc: 0.9938 - val_loss: 0.0904 - val_acc: 0.9781\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.97726 to 0.97808, saving model to encoded_data/weights-racism-improvement-02-0.9781.hdf5\n",
      "Epoch 3/10\n",
      "9852/9852 [==============================] - 149s 15ms/step - loss: 0.0112 - acc: 0.9975 - val_loss: 0.0988 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.97808\n",
      "Epoch 4/10\n",
      "9852/9852 [==============================] - 152s 15ms/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.1174 - val_acc: 0.9712\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97808\n",
      "Epoch 5/10\n",
      "9852/9852 [==============================] - 148s 15ms/step - loss: 0.0036 - acc: 0.9987 - val_loss: 0.1319 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97808 to 0.97929, saving model to encoded_data/weights-racism-improvement-05-0.9793.hdf5\n",
      "Epoch 6/10\n",
      "9852/9852 [==============================] - 152s 15ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1524 - val_acc: 0.9777\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97929\n",
      "Epoch 7/10\n",
      " 152/9852 [..............................] - ETA: 2:29 - loss: 1.1686e-04 - acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-1878189674cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m               \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m               \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m               validation_data = (x2_test, y2_racism_test_one_hot))\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "VOCAB_SIZE = 21351\n",
    "\n",
    "INP_DIM = x2_train.shape[1]\n",
    "EMBED_DIM = 128\n",
    "OP_DIM = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(VOCAB_SIZE, EMBED_DIM, input_length = INP_DIM))\n",
    "model.add(LSTM(200, dropout = 0.2, recurrent_dropout = 0.2))\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "\n",
    "# creating checkpoint to save model every time validation accuracy improves\n",
    "filepath = encoded_data_path + \"weights-racism-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "print('\\n\\nTraining Model...')\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#batch_size: Integer or None. Number of samples per gradient update. \n",
    "#If unspecified, batch_size will default to 32.\n",
    "\n",
    "model.fit(x2_train, y2_racism_train_one_hot,\n",
    "              batch_size = BATCH_SIZE,\n",
    "              epochs = EPOCHS,\n",
    "              callbacks = callbacks_list,\n",
    "              validation_data = (x2_test, y2_racism_test_one_hot))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2463,) (2463, 2) <class 'pandas.core.series.Series'> <class 'numpy.ndarray'>\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2037   16]\n",
      " [  35  375]]\n",
      "\n",
      "Classification Matrix:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.99      0.99      2053\n",
      "          1       0.96      0.91      0.94       410\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_lstm_racism = load_model(encoded_data_path +  'weights-racism-improvement-05-0.9793.hdf5')\n",
    "\n",
    "y2_predicted = model_lstm_racism.predict(x2_test)\n",
    "print(y2_racism_test.shape, y2_predicted.shape, type(y2_racism_test), type(y2_predicted))\n",
    "\n",
    "y2_predicted_ = y2_predicted.argmax(axis=1)\n",
    "\n",
    "print ('\\nConfusion Matrix:')\n",
    "print (confusion_matrix(y2_racism_test, y2_predicted_))\n",
    "\n",
    "\n",
    "print ('\\nClassification Matrix:')\n",
    "print (classification_report(y2_racism_test, y2_predicted_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9852/9852 [==============================] - 142s 14ms/step - loss: -12.4621 - hate_output_loss: 0.5704 - race_output_loss: 13.0324\n",
      "Epoch 2/10\n",
      "9852/9852 [==============================] - 126s 13ms/step - loss: -13.1731 - hate_output_loss: 0.1709 - race_output_loss: 13.3440\n",
      "Epoch 3/10\n",
      "9852/9852 [==============================] - 139s 14ms/step - loss: -13.2903 - hate_output_loss: 0.0545 - race_output_loss: 13.3447\n",
      "Epoch 4/10\n",
      "9852/9852 [==============================] - 124s 13ms/step - loss: -13.3184 - hate_output_loss: 0.0271 - race_output_loss: 13.3455\n",
      "Epoch 5/10\n",
      "9852/9852 [==============================] - 127s 13ms/step - loss: -13.3251 - hate_output_loss: 0.0204 - race_output_loss: 13.3455\n",
      "Epoch 6/10\n",
      "9852/9852 [==============================] - 137s 14ms/step - loss: -13.3302 - hate_output_loss: 0.0153 - race_output_loss: 13.3455\n",
      "Epoch 7/10\n",
      "9852/9852 [==============================] - 132s 13ms/step - loss: -13.3323 - hate_output_loss: 0.0133 - race_output_loss: 13.3455\n",
      "Epoch 8/10\n",
      "9852/9852 [==============================] - 130s 13ms/step - loss: -13.3340 - hate_output_loss: 0.0115 - race_output_loss: 13.3455\n",
      "Epoch 9/10\n",
      "9852/9852 [==============================] - 123s 12ms/step - loss: -13.3317 - hate_output_loss: 0.0137 - race_output_loss: 13.3454\n",
      "Epoch 10/10\n",
      "9852/9852 [==============================] - 123s 12ms/step - loss: -13.3334 - hate_output_loss: 0.0122 - race_output_loss: 13.3455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa2283b95c0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INP_DIM = x2_train.shape[1]\n",
    "\n",
    "input_hate = Input(shape=(INP_DIM,), name='input_hate')\n",
    "input_race = Input(shape=(INP_DIM,), name='input_race')\n",
    "\n",
    "x_hate = Embedding(output_dim=128, input_dim=VOCAB_SIZE, input_length = INP_DIM)(input_hate)\n",
    "x_race = Embedding(output_dim=128, input_dim=VOCAB_SIZE, input_length = INP_DIM)(input_race)\n",
    "\n",
    "lstm_hate_out = LSTM(100)(x_hate)\n",
    "lstm_race_out = LSTM(100)(x_race)\n",
    "\n",
    "x = concatenate([lstm_hate_out, lstm_race_out])\n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "#x = Dense(64, activation='relu')(x)\n",
    "\n",
    "hate_output = Dense(2, activation='softmax', name='hate_output')(x)\n",
    "race_output = Dense(2, activation='softmax', name='race_output')(x)\n",
    "\n",
    "#This defines a model with two inputs and two outputs:\n",
    "model = Model(inputs=[input_hate, input_race], outputs=[hate_output, race_output])\n",
    "\n",
    "\n",
    "#We compile the model and assign a weight of 0.2 to the auxiliary loss. \n",
    "#To specify different loss_weights or lossfor each different output, you can use a list or a dictionary. \n",
    "#Here we pass a single loss as the loss argument, so the same loss will be used on all outputs.\n",
    "\"\"\"\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
    "              loss_weights=[1., 0.2])\n",
    "\n",
    "#We can train the model by passing it lists of input arrays and target arrays:\n",
    "model.fit([headline_data, additional_data], [labels, labels],\n",
    "          epochs=50, batch_size=32)\n",
    "\"\"\"\n",
    "\n",
    "#Since our inputs and outputs are named (we passed them a \"name\" argument), \n",
    "#we could also have compiled the model via\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'hate_output': 'binary_crossentropy', 'race_output': 'binary_crossentropy'},\n",
    "              loss_weights={'hate_output': 1., 'race_output': -1.0})\n",
    "\n",
    "# And trained it via:\n",
    "model.fit({'input_hate': x2_train, 'input_race': x2_train},\n",
    "          {'hate_output': y2_hate_train_one_hot, 'race_output': y2_racism_train_one_hot},\n",
    "          epochs=10, batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[1083   83]\n",
      " [ 179 1118]]\n",
      "\n",
      "Classification Matrix:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.93      0.89      1166\n",
      "          1       0.93      0.86      0.90      1297\n",
      "\n",
      "avg / total       0.90      0.89      0.89      2463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Confusion Matrix:\n",
    "[[1024  142]\n",
    " [  91 1206]]\n",
    "\n",
    "Classification Matrix:\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.92      0.88      0.90      1166\n",
    "          1       0.89      0.93      0.91      1297\n",
    "\n",
    "avg / total       0.91      0.91      0.91      2463\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prediction = model.predict([x2_test, x2_test])\n",
    "x2_test.shape, prediction[0].shape, prediction[1].shape\n",
    "\n",
    "prediction = np.argmax(prediction[0], axis=1)\n",
    "\n",
    "print ('\\nConfusion Matrix:')\n",
    "print (confusion_matrix(y2_hate_test, prediction))\n",
    "\n",
    "\n",
    "print ('\\nClassification Matrix:')\n",
    "print (classification_report(y2_hate_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[   0 2053]\n",
      " [   0  410]]\n",
      "\n",
      "Classification Matrix:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00      2053\n",
      "          1       0.17      1.00      0.29       410\n",
      "\n",
      "avg / total       0.03      0.17      0.05      2463\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda5.2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([x2_test, x2_test])\n",
    "x2_test.shape, prediction[1].shape, prediction[1].shape\n",
    "\n",
    "prediction = np.argmax(prediction[1], axis=1)\n",
    "\n",
    "print ('\\nConfusion Matrix:')\n",
    "print (confusion_matrix(y2_racism_test, prediction))\n",
    "\n",
    "\n",
    "print ('\\nClassification Matrix:')\n",
    "print (classification_report(y2_racism_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9852/9852 [==============================] - 56s 6ms/step - loss: 13.3283 - hate_out_loss: 0.6276 - race_out_loss: 12.7007 - hate_out_acc: 0.6157 - race_out_acc: 0.1678: 16s - loss: 13.0503 - hate_out_loss: 0.6814 - race_out_loss: 12.3689 - hate_out_acc: 0 - ETA: 13s - loss: 13.1277 - hate_out_loss: 0.6772 - race_out_loss: 12.4506 -  - ETA: 8s - loss: 13.2032 - hate_out_loss: 0.6646 - race_out_loss: 12.5\n",
      "Epoch 2/10\n",
      "9852/9852 [==============================] - 54s 6ms/step - loss: 13.5510 - hate_out_loss: 0.1958 - race_out_loss: 13.3553 - hate_out_acc: 0.9266 - race_out_acc: 0.1669\n",
      "Epoch 3/10\n",
      "9852/9852 [==============================] - 54s 5ms/step - loss: 13.4309 - hate_out_loss: 0.0756 - race_out_loss: 13.3553 - hate_out_acc: 0.9744 - race_out_acc: 0.1669\n",
      "Epoch 4/10\n",
      "9852/9852 [==============================] - 53s 5ms/step - loss: 13.3985 - hate_out_loss: 0.0416 - race_out_loss: 13.3569 - hate_out_acc: 0.9867 - race_out_acc: 0.1668: 6s - loss: 13.3878 - hate_out_loss: 0.0391 - race_out_loss: 13.3487 - hate_ou\n",
      "Epoch 5/10\n",
      "9852/9852 [==============================] - 60s 6ms/step - loss: 13.3855 - hate_out_loss: 0.0296 - race_out_loss: 13.3559 - hate_out_acc: 0.9920 - race_out_acc: 0.1668\n",
      "Epoch 6/10\n",
      "9852/9852 [==============================] - 53s 5ms/step - loss: 13.3794 - hate_out_loss: 0.0251 - race_out_loss: 13.3543 - hate_out_acc: 0.9918 - race_out_acc: 0.1669\n",
      "Epoch 7/10\n",
      "9852/9852 [==============================] - 53s 5ms/step - loss: 13.3781 - hate_out_loss: 0.0204 - race_out_loss: 13.3576 - hate_out_acc: 0.9931 - race_out_acc: 0.1667: 5s - loss: 13.3859 - hate_out_loss: 0.0210 - race_out_loss: 13.3648 - hate_out_acc:  - ETA: 1s - loss: 13.3828 - hate_out_loss: 0.0208 - race_out_loss: 13.3620 - hate_out_acc: 0.9930 - race_out_acc: \n",
      "Epoch 8/10\n",
      "9852/9852 [==============================] - 55s 6ms/step - loss: 13.3764 - hate_out_loss: 0.0187 - race_out_loss: 13.3577 - hate_out_acc: 0.9936 - race_out_acc: 0.1667: 36s - loss: 13.3101 - hate - ETA: 28s - loss: 13.3544 - hate_out_loss: 0.0168 - race_out_loss: 13.3376 - hat - ETA: 25s - loss: 13.3529 - hate_out_loss: 0.0168 - race_out_loss: 13.3361 - hate_out_acc: 0.9946 - race_out_acc: 0. - ETA: 24s - loss: 13.\n",
      "Epoch 9/10\n",
      "9852/9852 [==============================] - 55s 6ms/step - loss: 13.3747 - hate_out_loss: 0.0169 - race_out_loss: 13.3578 - hate_out_acc: 0.9941 - race_out_acc: 0.1667: 12s - loss: 13.3431 - hate_out_loss: 0.0143 - race_out_loss: 13.3288 - hate_out_acc: 0.9 - ETA: 10s - loss: 13.3627 - hate_out_loss: 0.0157 - race_out_loss: 13.3470 - hate_out - ETA: 4s - loss: 13.3698 - hate_out_loss: 0.0162 - race_out_loss: 13.3536 - hate_out_acc: 0.994\n",
      "Epoch 10/10\n",
      "9852/9852 [==============================] - 55s 6ms/step - loss: 13.3739 - hate_out_loss: 0.0160 - race_out_loss: 13.3579 - hate_out_acc: 0.9948 - race_out_acc: 0.1667: 24s - loss: 13.3823 - hate_out_loss: 0.0141 - race_out_loss: 13.3682 - hate_out_acc: 0.9958  - ETA: 22s - loss: 13.3954 - hate_out_loss: 0.014 - ETA: 16s - loss: 13.4185 - hate_out_loss: 0 - ETA: 9s - loss: 13.3866 - hate_out_loss: 0.0158 - race_out_loss: 13.3708 - hate_out_acc: 0.9950 - race_out - ETA: 6s - loss: 13.3675 - hate_out_loss: 0.0159 - race_out_loss: 13.3516 - hate_ou - ETA: 0s - loss: 13.3716 - hate_out_loss: 0.0159 - race_out_loss: 13.3557 - hate_out_acc: 0.9950 - race_out_acc: 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6f4e661fd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#inp is a \"tensor\", that can be passed when calling other layers to produce an output \n",
    "inp = Input((10,)) #supposing you have ten numeric values as input \n",
    "\n",
    "\n",
    "#here, SomeLayer() is defining a layer, \n",
    "#and calling it with (inp) produces the output tensor x\n",
    "x = SomeLayer(blablabla)(inp) \n",
    "x = SomeOtherLayer(blablabla)(x) #here, I just replace x, because this intermediate output is not interesting to keep\n",
    "\n",
    "\n",
    "#here, I want to keep the two different outputs for defining the model\n",
    "#notice that both left and right are called with the same input x, creating a fork\n",
    "out1 = LeftSideLastLayer(balbalba)(x)    \n",
    "out2 = RightSideLastLayer(banblabala)(x)\n",
    "\n",
    "\n",
    "#here, you define which path you will follow in the graph you've drawn with layers\n",
    "#notice the two outputs passed in a list, telling the model I want it to have two outputs.\n",
    "model = Model(inp, [out1,out2])\n",
    "\"\"\"\n",
    "\n",
    "INP_DIM = x2_train.shape[1]\n",
    "\n",
    "inputs = Input(shape=(INP_DIM,), name='inp')\n",
    "inp = Embedding(output_dim=128, input_dim=VOCAB_SIZE, input_length = INP_DIM)(inputs)\n",
    "\n",
    "inp = LSTM(100)(inp)\n",
    "\n",
    "race_out = Dense(64)(inp)\n",
    "hate_out = Dense(64)(inp)\n",
    "\n",
    "#GRL for race\n",
    "Flip = GradientReversal(1)\n",
    "race_out = Flip(race_out)\n",
    "\n",
    "#x = concatenate([hate_out, race_out])\n",
    "#x = Dense(64, activation='relu')(x)\n",
    "\n",
    "hate_out = Dense(2, activation='softmax', name='hate_out')(hate_out)\n",
    "race_out = Dense(2, activation='softmax', name='race_out')(race_out)\n",
    "\n",
    "#This defines a model with two inputs and two outputs:\n",
    "model = Model(inputs, outputs=[hate_out, race_out])\n",
    "\n",
    "\n",
    "#We compile the model and assign a weight of 0.2 to the auxiliary loss. \n",
    "#To specify different loss_weights or lossfor each different output, you can use a list or a dictionary. \n",
    "#Here we pass a single loss as the loss argument, so the same loss will be used on all outputs.\n",
    "\"\"\"\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n",
    "              loss_weights=[1., 0.2])\n",
    "\n",
    "#We can train the model by passing it lists of input arrays and target arrays:\n",
    "model.fit([headline_data, additional_data], [labels, labels],\n",
    "          epochs=50, batch_size=32)\n",
    "\"\"\"\n",
    "\n",
    "#Since our inputs and outputs are named (we passed them a \"name\" argument), \n",
    "#we could also have compiled the model via\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'hate_out': 'binary_crossentropy', 'race_out': 'binary_crossentropy'},\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "# creating checkpoint to save model every time validation accuracy improves\n",
    "#filepath = encoded_data_path + \"weights-GRL-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "# And trained it via:\n",
    "model.fit({'inp': x2_train},\n",
    "          {'hate_out': y2_hate_train_one_hot, 'race_out': y2_racism_train_one_hot},\n",
    "          epochs=10, \n",
    "          batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'hate_out_loss', 'race_out_loss', 'hate_out_acc', 'race_out_acc'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history  = model.history\n",
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loss history\n",
    "plt.figure(figsize=(20,20), dpi=80)\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['hate_out_loss'])\n",
    "plt.plot(history.history['race_out_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.xlim([0, 10])\n",
    "plt.ylim([-15, 15])\n",
    "plt.xticks(np.arange(0,10,2))\n",
    "plt.yticks(np.arange(-15,15,2))\n",
    "\n",
    "plt.legend(['loss', 'hate_out_loss', 'race_out_loss'], loc='upper left', prop={'size': 10})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aw, snap! We didn't get a username with your request.\n",
      "\n",
      "Don't have an account? https://plot.ly/api_signup\n",
      "\n",
      "Questions? accounts@plot.ly\n"
     ]
    },
    {
     "ename": "PlotlyError",
     "evalue": "Because you didn't supply a 'file_id' in the call, we're assuming you're trying to snag a figure from a url. You supplied the url, '', we expected it to start with 'https://plot.ly'.\nRun help on this function for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPlotlyError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-dd05f1bdd068>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\plotly\\plotly\\plotly.py\u001b[0m in \u001b[0;36miplot\u001b[1;34m(figure_or_data, **plot_options)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0membed_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'height'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'height'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'px'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0membed_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\plotly\\tools.py\u001b[0m in \u001b[0;36membed\u001b[1;34m(file_owner_or_url, file_id, width, height)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m             \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_owner_or_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mPlotlyDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m         if (get_config_defaults()['plotly_domain']\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\plotly\\tools.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, url, width, height)\u001b[0m\n\u001b[0;32m   1450\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1452\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_embed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1453\u001b[0m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPlotlyDisplay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_code\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda5.2\\lib\\site-packages\\plotly\\tools.py\u001b[0m in \u001b[0;36mget_embed\u001b[1;34m(file_owner_or_url, file_id, width, height)\u001b[0m\n\u001b[0;32m    303\u001b[0m                 \u001b[1;34m\"'{1}'.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m                 \u001b[1;34m\"\\nRun help on this function for more information.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m                 \"\".format(url, plotly_rest_url))\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[0murlsplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[0mfile_owner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlsplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'~'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPlotlyError\u001b[0m: Because you didn't supply a 'file_id' in the call, we're assuming you're trying to snag a figure from a url. You supplied the url, '', we expected it to start with 'https://plot.ly'.\nRun help on this function for more information."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "history  = model.history\n",
    "\n",
    "# x + y = 8  => y = 8 - x => straight line in x-y axes with slope = -1\n",
    "#log(x) vs log(y) will be a decreasing curve \n",
    "trace0 = go.Scatter(\n",
    "    x= np.arange(0,20,1),\n",
    "    y= history.history['loss']\n",
    ")\n",
    "\n",
    "\n",
    "# y = x => log(y) = 1.log(x); so slope of graph will be 1 and it will be straight line.\n",
    "trace1 = go.Scatter(\n",
    "    x= np.arange(0,20,1),\n",
    "    y= history.history['hate_out_loss']\n",
    ")\n",
    "\n",
    "trace2 = go.Scatter(\n",
    "    x= np.arange(0,20,1),\n",
    "    y= history.history['race_out_loss']\n",
    ")\n",
    "\n",
    "data = [trace0, trace1, trace2]\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        autorange=True\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        autorange=True\n",
    "    )\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2463, 20) (2463, 2) (2463, 2)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1050   97]\n",
      " [ 205 1111]]\n",
      "\n",
      "Classification Matrix:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.92      0.87      1147\n",
      "          1       0.92      0.84      0.88      1316\n",
      "\n",
      "avg / total       0.88      0.88      0.88      2463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Confusion Matrix:\n",
    "[[1083   83]\n",
    " [ 179 1118]]\n",
    "\n",
    "Classification Matrix:\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "          0       0.86      0.93      0.89      1166\n",
    "          1       0.93      0.86      0.90      1297\n",
    "\n",
    "avg / total       0.90      0.89      0.89      2463\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prediction = model.predict(x2_test)\n",
    "print(x2_test.shape, prediction[0].shape, prediction[1].shape)\n",
    "\n",
    "prediction = np.argmax(prediction[0], axis=1)\n",
    "\n",
    "print ('\\nConfusion Matrix:')\n",
    "print (confusion_matrix(y2_hate_test, prediction))\n",
    "\n",
    "\n",
    "print ('\\nClassification Matrix:')\n",
    "print (classification_report(y2_hate_test, prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2463, 20) (2463, 2) (2463, 2)\n",
      "\n",
      "Confusion Matrix:\n",
      "[[   1 2031]\n",
      " [   0  431]]\n",
      "\n",
      "Classification Matrix:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.00      0.00      2032\n",
      "          1       0.18      1.00      0.30       431\n",
      "\n",
      "avg / total       0.86      0.18      0.05      2463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(x2_test)\n",
    "print(x2_test.shape, prediction[1].shape, prediction[1].shape)\n",
    "\n",
    "prediction = np.argmax(prediction[1], axis=1)\n",
    "\n",
    "print ('\\nConfusion Matrix:')\n",
    "print (confusion_matrix(y2_racism_test, prediction))\n",
    "\n",
    "\n",
    "print ('\\nClassification Matrix:')\n",
    "print (classification_report(y2_racism_test, prediction))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet                                    Y-H        Y-R        Y-S        Y'-H       Y'-R      \n",
      "\n",
      "peopl poke yesterday eyebal meeting      0          0          0          1          1         \n",
      "\n",
      "mikemetcalf love misti morn blizzar      0          0          0          0          1         \n",
      "\n",
      "jukes303 unlik read make assumption      1          1          0          0          1         \n",
      "\n",
      "hafisabidre anim slit throat suppos      1          1          0          1          1         \n",
      "\n",
      "lavender_blum man applaud blameonen      0          0          0          0          1         \n",
      "\n",
      "onnionion i'll readi minut girl usu      1          0          1          0          1         \n",
      "\n",
      "srhbutt poor grimachu. date sjws bo      0          0          0          0          1         \n",
      "\n",
      "buttercupashbi madasahatter_17 moha      1          1          0          0          1         \n",
      "\n",
      "shut kati nikki... mkr mkr2015 myki      1          0          1          1          1         \n",
      "\n",
      "offense. nigelbigmeech i'm sexist w      1          0          1          0          1         \n",
      "\n",
      "vandalis sajid_fairooz israeliregim      1          1          0          0          1         \n",
      "\n",
      "warrior_tank randi 1266                  0          0          0          0          1         \n",
      "\n",
      "mykitchenrul find kati nikki line d      1          0          1          1          1         \n",
      "\n",
      "fee_bee_63 kat complet rank cow god      1          0          1          1          1         \n",
      "\n",
      "lrt appear snark. o_o. pretti sure       0          0          0          1          1         \n",
      "\n",
      "canine_right kizzycoy1 exact europ       1          1          0          0          1         \n",
      "\n",
      "feminazi snowflak feminazi snowflak      1          0          1          1          1         \n",
      "\n",
      "srhbutt thatsabinegirl yeah sound l      1          0          1          0          1         \n",
      "\n",
      "comment found mra notic employ name      0          0          0          0          1         \n",
      "\n",
      "the_duke_gam press request need com      0          0          0          1          1         \n",
      "\n",
      "theeaglesfan005 kbeelrsreiyen fault      1          0          1          0          1         \n",
      "\n",
      "tobyfe justkelly_ok use end brain b      0          0          0          0          1         \n",
      "\n",
      "lost questionsformen essenti ford w      1          0          1          1          1         \n",
      "\n",
      "theapgam feminazi                        0          0          0          1          1         \n",
      "\n",
      "theomegakira slashdot look like am.      0          0          0          1          1         \n",
      "\n",
      "essenti amiabl disposit main coon a      0          0          0          1          1         \n",
      "\n",
      "huffpostrelig islam invad conquer c      1          1          0          0          1         \n",
      "\n",
      "madtrophywif content warning.            0          0          0          1          1         \n",
      "\n",
      "dustype mrtimothykay think hashtag       1          0          1          0          1         \n",
      "\n",
      "suck whore mkr                           1          0          1          1          1         \n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_sexism = data['sexism']\n",
    "\n",
    "prediction = model.predict(x2_test)\n",
    "\n",
    "prediction_hate = np.argmax(prediction[0], axis=1)\n",
    "prediction_race = np.argmax(prediction[1], axis=1)\n",
    "\n",
    "\n",
    "print(\"{0: <40} {1: <10} {2: <10} {3: <10} {4: <10} {5: <10}\\n\".format(\"Tweet\", \"Y-H\", \"Y-R\", \"Y-S\", \"Y'-H\", \"Y'-R\"))\n",
    "\n",
    "\n",
    "for i in range(30):    \n",
    "    print(\"{0: <40} {1: <10} {2: <10} {3: <10} {4: <10} {5: <10}\\n\".format(data['tweet'][i][:35], labels_hate[i], labels_racist[i],\n",
    "                                                        labels_sexism[i], prediction_hate[i], prediction_race[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "ToC",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
