{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "## Plot\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "import matplotlib as plt\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import Stemmer\n",
    "\n",
    "# Other\n",
    "import re\n",
    "import timeit\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 7 columns):\n",
      "index                 24783 non-null int64\n",
      "count                 24783 non-null int64\n",
      "hate_speech           24783 non-null int64\n",
      "offensive_language    24783 non-null int64\n",
      "neither               24783 non-null int64\n",
      "class                 24783 non-null int64\n",
      "tweet                 24783 non-null object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"labeled_data.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "data['hate+offensive_count'] = df['offensive_language']\n",
    "data['non-hate_count'] = df['neither']\n",
    "\n",
    "classes = []\n",
    "for index, row in data.iterrows():\n",
    "    temp = 1 if row['hate+offensive_count'] > row['non-hate_count'] else 0\n",
    "    classes.append(temp)\n",
    "    \n",
    "data['class'] = classes\n",
    "\n",
    "#label =  {1:hate, 0:non-hate}\n",
    "labels = data['class'].map(lambda x : 1 if int(x) == 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopWords = set(stopwords.words(\"english\"))\n",
    "stemmer = Stemmer.Stemmer('english', 100000)    \n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    ## Remove puncuation\n",
    "    #text = text.translate(string.punctuation)\n",
    "    \n",
    "    #split based on everything except a-z0-9_'.\\-\n",
    "    #tokens = re.findall(\"[a-z0-9_'.\\-]+\", text.lower())\n",
    "    tokens = text.lower().split()\n",
    "    \n",
    "    tokens = [stemmer.stemWord(w) for w in tokens if not w in stopWords and len(w) > 2 and len(w)<20]\n",
    "    text = \" \".join(tokens)\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "#cleaning text\n",
    "data['tweet'] = df['tweet'].map(lambda x: clean_text(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 4 columns):\n",
      "hate+offensive_count    24783 non-null int64\n",
      "non-hate_count          24783 non-null int64\n",
      "class                   24783 non-null int64\n",
      "tweet                   24783 non-null object\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 774.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate+offensive_count</th>\n",
       "      <th>non-hate_count</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>mayasolov woman complain clean hous amp; man a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mleew17 boy dat cold tyga dwn bad cuffin dat h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>urkindofbrand dawg 80sbaby4lif ever fuck bitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>anderson viva base look like tranni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>shenikarobert shit hear might true might faker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>madison shit blow claim faith somebodi still f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>brighterday sit hate anoth bitch got much shit go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8220; selfiequeenbri caus tire big bitch come ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>amp; might get bitch back amp; that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rhythmixx hobbi includ fight mariam bitch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hate+offensive_count  non-hate_count  class  \\\n",
       "0                     0               3      0   \n",
       "1                     3               0      1   \n",
       "2                     3               0      1   \n",
       "3                     2               1      1   \n",
       "4                     6               0      1   \n",
       "5                     2               0      1   \n",
       "6                     3               0      1   \n",
       "7                     3               0      1   \n",
       "8                     3               0      1   \n",
       "9                     2               0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  mayasolov woman complain clean hous amp; man a...  \n",
       "1  mleew17 boy dat cold tyga dwn bad cuffin dat h...  \n",
       "2  urkindofbrand dawg 80sbaby4lif ever fuck bitch...  \n",
       "3                anderson viva base look like tranni  \n",
       "4  shenikarobert shit hear might true might faker...  \n",
       "5  madison shit blow claim faith somebodi still f...  \n",
       "6  brighterday sit hate anoth bitch got much shit go  \n",
       "7  8220; selfiequeenbri caus tire big bitch come ...  \n",
       "8                amp; might get bitch back amp; that  \n",
       "9          rhythmixx hobbi includ fight mariam bitch  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info()\n",
    "data.head(10)\n",
    "\n",
    "#print(len(labels), len(data['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"cleaned_tweets1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample):\n",
    "    \n",
    "    print(\"\\nGiven sample size:\", len(sample))\n",
    "    \n",
    "    #Keras tokenizer function to tokenize the strings and \n",
    "    #‘texts_to_sequences’ to make sequences of words.\n",
    "\n",
    "    vocabulary_size = 20000\n",
    "\n",
    "    #Maximum number of words to work with \n",
    "    #(if set, tokenization will be restricted to the top nb_words most common words in the dataset).\n",
    "    tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "\n",
    "    #fit_on_texts(texts):\n",
    "    #Arguments: list of texts to train on.\n",
    "    #tokenizer.fit_on_texts(data['tweet'])\n",
    "    tokenizer.fit_on_texts(sample)\n",
    "\n",
    "    #texts_to_sequences(texts)\n",
    "    #texts: list of texts to turn to sequences.\n",
    "    #Return: list of sequences (one per text input).\n",
    "    \n",
    "    #sequences = tokenizer.texts_to_sequences(data['tweet'])\n",
    "    sequences = tokenizer.texts_to_sequences(sample)\n",
    "    sample = pad_sequences(sequences, maxlen=50)\n",
    "    \n",
    "    print(\"Processed sample shape:\", sample.shape)\n",
    "    print(\"Sample1:\", sample[0])\n",
    "    \n",
    "    return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "24783\n",
      "<class 'pandas.core.series.Series'>\n",
      "10\n",
      "Train data len: 19826 \n",
      "Test data len: 4957\n",
      "mayasolov woman complain clean hous amp; man alway take trash\n",
      "\n",
      "Given sample size: 19826\n",
      "Processed sample shape: (19826, 50)\n",
      "Sample1: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 2]\n",
      "\n",
      "Given sample size: 4957\n",
      "Processed sample shape: (4957, 50)\n",
      "Sample1: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      " 3503 3504 3505 1271 2194 3506 1608   17]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 2]\n"
     ]
    }
   ],
   "source": [
    "print(type(data['tweet']))\n",
    "print(len(data['tweet']))\n",
    "\n",
    "print(type(data['tweet'][0:10]))\n",
    "print(len(data['tweet'][0:10]))\n",
    "\n",
    "#sklearn.model_selection.train_test_split(*arrays, **options)[source]\n",
    "\n",
    "#*arrays : sequence of indexables with same length / shape[0]\n",
    "#Allowed inputs are lists, numpy arrays, scipy-sparse matrices or pandas dataframes.\n",
    "\n",
    "#test_size/train_size \n",
    "#If float, should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split. \n",
    "#If int, represents the absolute number of test samples. \n",
    "#If None, the value is set to the complement of the train size\n",
    "\n",
    "#shuffle : boolean, optional (default=True)\n",
    "#Whether or not to shuffle the data before splitting. If shuffle=False then stratify must be None.\n",
    "\n",
    "#splitting : list, length=2 * len(arrays)\n",
    "#List containing train-test split of inputs.\n",
    "\n",
    "\n",
    "X = data['tweet']\n",
    "Y = labels\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "print(\"Train data len:\", len(X_train), \"\\nTest data len:\", len(X_test))\n",
    "\n",
    "print(X_train[0])\n",
    "X_train = process_sample(X_train)\n",
    "X_test = process_sample(X_test)\n",
    "\n",
    "print(X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Train data len: 19826 , Test data len: 4957\n",
      "\n",
      "\n",
      "Training Model...\n",
      "Train on 19826 samples, validate on 4957 samples\n",
      "Epoch 1/3\n",
      "19826/19826 [==============================] - 3s 134us/step - loss: 3.2536 - acc: 0.7940 - val_loss: 3.0068 - val_acc: 0.8114\n",
      "Epoch 2/3\n",
      "19826/19826 [==============================] - 1s 69us/step - loss: 2.9054 - acc: 0.8178 - val_loss: 3.0071 - val_acc: 0.8114\n",
      "Epoch 3/3\n",
      "19826/19826 [==============================] - 1s 69us/step - loss: 2.9053 - acc: 0.8178 - val_loss: 3.0071 - val_acc: 0.8114\n",
      "\n",
      "\n",
      "Total training time: 5.9940 seconds.\n",
      "4957/4957 [==============================] - 0s 26us/step\n",
      "\n",
      "Testing time: 0.1332 seconds.\n",
      "\n",
      "Test score: 3.007087031607429\n",
      "Test accuracy: 0.8113778494215791\n"
     ]
    }
   ],
   "source": [
    "#The network starts with an embedding layer. \n",
    "#The layer lets the system expand each token to a more massive vector, \n",
    "#allowing the network to represent a word in a meaningful way. \n",
    "#The layer takes 20000 as the first argument, which is the size of our vocabulary, \n",
    "#and 100 as the second input parameter, which is the dimension of the embedding i.e. output_dim\n",
    "#The third parameter is the input_length of 50, which is the length of each comment sequence.\n",
    "\n",
    "## Network architecture\n",
    "print('Building model...')\n",
    "model_mlp = Sequential()\n",
    "\n",
    "max_features = 20000 #size of vocab\n",
    "\n",
    "#Embedding(input_dim, output_dim, embeddings_initializer='uniform', ***, input_length=None)\n",
    "#o/p will be model.output_shape == (None, 10 :input_dim, 64:output_dim), where None is the batch dimension of the matrix given.\n",
    "#model_mlp.add(Embedding(max_features, 100, input_length=50))\n",
    "\n",
    "## Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape: here, 20-dimensional vectors.\n",
    "model_mlp.add(Dense(64, input_dim= 50, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "\n",
    "model_mlp.add(Dense(64, activation='relu'))\n",
    "model_mlp.add(Dropout(0.5))\n",
    "\n",
    "model_mlp.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_mlp.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print(\"Train data len:\", len(X_train), \", Test data len:\", len(X_test))\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print('\\n\\nTraining Model...')\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#batch_size: Integer or None. Number of samples per gradient update. \n",
    "#If unspecified, batch_size will default to 32.\n",
    "model_mlp.fit(X_train, Y_train,\n",
    "              batch_size = BATCH_SIZE,\n",
    "              epochs = EPOCHS,\n",
    "              validation_data=(X_test, Y_test))\n",
    "\n",
    "#model_lstm.fit(data, np.array(labels), validation_split=0.2, epochs=3)\n",
    "\n",
    "print(\"\\n\\nTotal training time: %.4f seconds.\" % (timeit.default_timer() - start))\n",
    "\n",
    "\n",
    "start = timeit.default_timer()\n",
    "score, acc = model_mlp.evaluate(X_test, Y_test, batch_size = BATCH_SIZE)\n",
    "\n",
    "print(\"\\nTesting time: %.4f seconds.\" % (timeit.default_timer() - start))\n",
    "print('\\nTest score:', score)\n",
    "print('Test accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Train data len: 19826 , Test data len: 4957\n",
      "\n",
      "\n",
      "Training Model...\n",
      "Train on 19826 samples, validate on 4957 samples\n",
      "Epoch 1/3\n",
      "19826/19826 [==============================] - 76s 4ms/step - loss: 0.2131 - acc: 0.9152 - val_loss: 0.3685 - val_acc: 0.8443\n",
      "Epoch 2/3\n",
      "19826/19826 [==============================] - 88s 4ms/step - loss: 0.1387 - acc: 0.9517 - val_loss: 0.3545 - val_acc: 0.8416\n",
      "Epoch 3/3\n",
      "19826/19826 [==============================] - 89s 4ms/step - loss: 0.1275 - acc: 0.9553 - val_loss: 0.3854 - val_acc: 0.8374\n",
      "\n",
      "\n",
      "Total training time: 254.8442 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Network architecture\n",
    "print('Building model...')\n",
    "model_lstm = Sequential()\n",
    "\n",
    "#The network starts with an embedding layer.\n",
    "#Turns positive integers (indexes) into dense vectors of fixed size allowing the n/w to represent a word in a meaningful way.\n",
    "#eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]\n",
    "#This layer can only be used as the first layer in a model.\n",
    "\n",
    "#keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', ***, input_length=None)\n",
    "\n",
    "#input_dim: int > 0. Size of the vocabulary, i.e. maximum integer index + 1.\n",
    "\n",
    "#output_dim: int >= 0. Dimension of the dense embedding.\n",
    "\n",
    "#input_length: Length of input sequences, when it is constant. \n",
    "#This argument is required if you are going to connect Flatten then Dense layers upstream \n",
    "#(without it, the shape of the dense outputs cannot be computed).\n",
    "\n",
    "#eg. model.add(Embedding(1000, 64, input_length=10))\n",
    "\n",
    "# the model will take as input an integer matrix of size (batch, input_length).\n",
    "# where the largest integer (i.e. word index) in the input should be no larger than 999 (vocabulary size).\n",
    "\n",
    "# o/p will be model.output_shape == (None, 10 :input_dim, 64:output_dim), where None is the batch dimension of the matrix given.\n",
    "\n",
    "\n",
    "model_lstm.add(Embedding(20000, 100, input_length=50))\n",
    "model_lstm.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "print(\"Train data len:\", len(X_train), \", Test data len:\", len(X_test))\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print('\\n\\nTraining Model...')\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "#batch_size: Integer or None. Number of samples per gradient update. \n",
    "#If unspecified, batch_size will default to 32.\n",
    "model_lstm.fit(X_train, Y_train,\n",
    "              batch_size = BATCH_SIZE,\n",
    "              epochs = EPOCHS,\n",
    "              validation_data=(X_test, Y_test))\n",
    "\n",
    "#model_lstm.fit(data, np.array(labels), validation_split=0.2, epochs=3)\n",
    "\n",
    "print(\"\\n\\nTotal training time: %.4f seconds.\" % (timeit.default_timer() - start))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4957/4957 [==============================] - 3s 620us/step\n",
      "\n",
      "Testing time: 3.0772 seconds.\n",
      "\n",
      "Test score: 0.38537159742475974\n",
      "Test accuracy: 0.8374016542503953\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "score, acc = model_lstm.evaluate(X_test, Y_test, batch_size = BATCH_SIZE)\n",
    "\n",
    "print(\"\\nTesting time: %.4f seconds.\" % (timeit.default_timer() - start))\n",
    "print('\\nTest score:', score)\n",
    "print('Test accuracy:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given sample size: 50\n",
      "Processed sample shape: (50, 50)\n",
      "Sample1: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 42 43 44 45 46  9 47 48\n",
      " 49 50]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "model.predict(x, batch_size=None, verbose=0, steps=None)\n",
    "Generates output predictions for the input samples.\n",
    "\n",
    "Computation is done in batches.\n",
    "\n",
    "Arguments\n",
    "\n",
    "x: The input data, as a Numpy array (or list of Numpy arrays if the model has multiple inputs).\n",
    "\n",
    "batch_size: Integer. If unspecified, it will default to 32.\n",
    "\n",
    "verbose: Verbosity mode, 0 or 1.\n",
    "\n",
    "steps: Total number of steps (batches of samples) before declaring the prediction round finished. \n",
    "Ignored with the default value of None.\n",
    "\n",
    "Returns: Numpy array(s) of predictions.\n",
    "\n",
    "Raises\n",
    "\n",
    "ValueError: In case of mismatch between the provided input data and the model's expectations, \n",
    "or in case a stateful model receives a number of samples that is not a multiple of the batch size.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sample = process_sample(data['tweet'][0:50])\n",
    "model_lstm.predict_classes(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
